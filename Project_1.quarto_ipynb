{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Cubic Zirconia Price Analysis\"\n",
        "format: gfm\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "The goal of this analysis is to explore the relationships between cubic zirconia gemstone characteristics (e.g., `carat`, `cut`, `color`, `clarity`) and price. The analysis emphasizes inference, focusing on identifying significant predictors and understanding their relationships while ensuring statistical rigor.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "```{r}\n",
        "# Load required libraries\n",
        "library(tidyverse)\n",
        "library(car) \n",
        "library(dplyr)\n",
        "library(MASS) \n",
        "library(gridExtra)\n",
        "```\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "\n",
        "```{r}\n",
        "path <- \"cubic_zirconia.csv\"\n",
        "\n",
        "data <- read_csv(file = path, col_names = TRUE)\n",
        "head(data)\n",
        "```\n",
        "\n",
        "\n",
        "Response Variable:\n",
        "\n",
        "```         \n",
        "Price : the Price of the cubic zirconia.\n",
        "```\n",
        "\n",
        "Possible Covariates:\n",
        "\n",
        "```         \n",
        "Carat : Carat weight of the cubic zirconia.\n",
        "\n",
        "Cut : Describe the cut quality of the cubic zirconia. Quality is increasing order Fair, Good, Very Good, Premium, Ideal.\n",
        "\n",
        "Color: Colour of the cubic zirconia.With D being the best and J the worst.\n",
        "\n",
        "Clarity : cubic zirconia Clarity refers to the absence of the Inclusions and Blemishes. (In order from Best to Worst, FL = flawless, I3= level 3 inclusions) - FL, IF, VVS1, VVS2, VS1, VS2, SI1, SI2, I1, I2, I3\n",
        "\n",
        "Depth : The Height of a cubic zirconia, measured from the Culet to the table, divided by its average Girdle Diameter.\n",
        "\n",
        "Table : The Width of the cubic zirconia's Table expressed as a percentage of its Average Diameter.\n",
        "\n",
        "X : Length of the cubic zirconia in mm.\n",
        "\n",
        "Y : Width of the cubic zirconia in mm.\n",
        "\n",
        "Z : Height of the cubic zirconia in mm.\n",
        "```\n",
        "\n",
        "# Clean the dataset\n",
        "\n",
        "\n",
        "```{r}\n",
        "#Removing row count column\n",
        "data <- data[-1]\n",
        "head(data)\n",
        "```\n",
        "\n",
        "\n",
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Summary Statistics\n",
        "\n",
        "\n",
        "```{r}\n",
        "print(str_glue (\"There are {nrow(data)} rows in the dataset.\\n\\n\"))\n",
        "print(str_glue(\"There are {sum(is.na(data))} total missing values in the dataset.\\n Total missing values per column:\\n\\n\"))\n",
        "\n",
        "print(colSums(is.na(data)))\n",
        "data <- data |> drop_na(depth)\n",
        "print(colSums(is.na(data)))\n",
        "```\n",
        "\n",
        "\n",
        "# Correcting Column Data Types\n",
        "\n",
        "\n",
        "```{r}\n",
        "\n",
        "data$cut <- factor(data$cut, levels = c(\"Ideal\", \"Premium\", \"Very Good\", \"Good\", \"Fair\"))\n",
        "data$color <- factor(data$color, levels = c(\"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"))\n",
        "data$clarity <- factor(data$clarity, levels = c(\"FL\", \"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\", \"I2\", \"I3\"))\n",
        "\n",
        "head(data)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "## Distributions of Variables\n",
        "\n",
        "\n",
        "```{r}\n",
        "# Function to calculate proportions and create a plot\n",
        "create_proportion_plot <- function(var, var_name) {\n",
        "  prop_table <- prop.table(table(var)) * 100\n",
        "  prop_df <- as.data.frame(prop_table)\n",
        "  colnames(prop_df) <- c(var_name, \"proportion\")\n",
        "  \n",
        "  ggplot(prop_df, aes(x = get(var_name), y = proportion)) +\n",
        "    geom_bar(stat = \"identity\", fill = \"purple\", color = \"white\") +\n",
        "    labs(x = var_name, y = \"Proportion (%)\", title = str_glue(\"Proportion of Categories in {str_to_title(var_name)}\")) +\n",
        "    theme_minimal() +\n",
        "    theme(axis.text.x = element_text(angle = 45, hjust = 1),\n",
        "         text = element_text(size = 15)) \n",
        "}\n",
        "\n",
        "p1 <- create_proportion_plot(data$clarity, \"clarity\")\n",
        "p2 <- create_proportion_plot(data$cut, \"cut\")\n",
        "p3 <- create_proportion_plot(data$color, \"color\")\n",
        "\n",
        "grid.arrange(p1, p2, p3, nrow = 1, ncol = 3, widths = c(8, 8, 8), heights = c(8))\n",
        "```\n",
        "\n",
        "\n",
        "The graphs above indicate that the categories within each categorical variable are not equally represented in the data.\n",
        "\n",
        "\n",
        "```{r}\n",
        "ggplot(data, aes(x = price)) + \n",
        "  geom_histogram(bins = 15, fill = \"purple\", color = \"white\") +\n",
        "  labs(x = \"Price ($)\", y = \"Count\", title = \"Price Distribution\") + \n",
        "  theme(text = element_text(size = 16)) +\n",
        "  geom_vline(aes(xintercept = mean(price), color = \"Mean\"), linetype = \"dashed\", size = 1) + \n",
        "  geom_vline(aes(xintercept = median(price), color = \"Median\"), linetype = \"dashed\", size = 1) + \n",
        "  scale_color_manual(values = c(\"Mean\" = \"red\", \"Median\" = \"blue\")) +\n",
        "  theme(legend.title = element_text(size = 14), legend.text = element_text(size = 12))\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "The above histogram for the response variable, Price, shows a right skewed distribution. The mean is higher than the median.\n",
        "\n",
        "## Relationships Between Variables\n",
        "\n",
        "\n",
        "```{r}\n",
        "# graphing all continuous variables against price (the response)\n",
        "\n",
        "continuous_vars = c('carat', 'depth', 'table', 'x', 'y', 'z')\n",
        "labels = c('Carat', 'Depth', 'Table (%)', 'Length (mm)', 'Width (mm)', 'Height (mm)')\n",
        "\n",
        "plot_list <- list()\n",
        "\n",
        "for (i in 1:length(continuous_vars)) {\n",
        "    p <- ggplot(data = data, aes(x = .data[[continuous_vars[i]]], y = price)) +\n",
        "            geom_point(color = \"purple\", alpha = 0.2) + \n",
        "            labs(x = labels[i], y = \"Price ($)\", title = str_glue(\"Price vs {stringr::str_to_title(continuous_vars[i])}\")) + \n",
        "            theme(text = element_text(size = 12))\n",
        "    plot_list[[i]] <- p\n",
        "}\n",
        "\n",
        "grid.arrange(grobs = plot_list, nrow = 3, col = 2)\n",
        "```\n",
        "\n",
        "todo\n",
        "\n",
        "```{r}\n",
        "cat_vars = c('cut', 'color', 'clarity')\n",
        "\n",
        "for (i in 1:length(cat_vars)) {\n",
        "    p <- ggplot(data = data, aes(x = .data[[cat_vars[i]]], y = price, color = .data[[cat_vars[i]]])) +\n",
        "            geom_boxplot(alpha = 0.5) + \n",
        "            labs(x = stringr::str_to_title(cat_vars[i]), y = \"Price ($)\", title = str_glue(\"Price vs {stringr::str_to_title(cat_vars[i])}\")) + \n",
        "            theme(text = element_text(size = 15))\n",
        "    print(p)\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "There appears to be a lot of overlap between boxplots in the cut and color plots. This suggests there might not be a strong relationship between different cut and color categories and price. However, there seems to be less overlap between boxes in the clarity plot. For example, there is almost no overlap between the IF (internally flawless) and I1 (level 1 inclusions) categories. This indicates that clarity may be a stronger predictor of price. This is intuitive because gemstones with higher clarity are generally more expensive. Cut and color may not be as strongly correlated with price.\n",
        "\n",
        "It is interesting to note that in the third plot of price vs clarity, the median price for IF gemstones is lower than the median price for I1 gemstones. This however, is counterintuitive because a flawless gemstone should have the highest price.\n",
        "\n",
        "The following graph suggests that the lower price for IF gemstones may have been because of lower weights of such cubic zirconia being bought. This suggests there may be some interaction between weight of the gemstone and its clarity in determining the price of a gemstone.\n",
        "\n",
        "\n",
        "```{r}\n",
        "ggplot(data = data, aes(x = clarity, y = carat, color = clarity)) +\n",
        "            geom_boxplot(alpha = 0.5) + \n",
        "            labs(x = \"Clarity\", y = \"Weight (carat)\", title = \"Carat vs Clarity\") + \n",
        "            theme(text = element_text(size = 15))\n",
        "```\n",
        "\n",
        "```{r}\n",
        "ggplot(data, aes(x = carat, y = price)) + geom_point(alpha = 0.5) + geom_smooth(method = \"lm\", col = \"red\") + labs(title = \"Price vs Carat\")\n",
        "```\n",
        "\n",
        "Based on the graph above, we assume that the model to be linear (i.e we do not include higher degree term in our model). There is a slight curve in the graph, so we have decided to include the interaction between carat and clarity to introduce some non-linearity.\n",
        "\n",
        "# Multicollinearity Analysis\n",
        "\n",
        "## Variance Inflation Factor (VIF)\n",
        "\n",
        "\n",
        "```{r}\n",
        "model_initial <- lm(price ~ carat + color + cut + clarity + depth + table + x + y + z, data = data)\n",
        "\n",
        "vif_values <- vif(model_initial)\n",
        "print(vif_values)\n",
        "```\n",
        "\n",
        "\n",
        "-   `carat`: **22.79** → Severe multicollinearity.\n",
        "\n",
        "-   `x`, `z`: **92.71** and **78.46** → Extremely severe multicollinearity.\n",
        "\n",
        "-   `y`: **14.53** → Moderate to severe multicollinearity.\n",
        "\n",
        "-   `depth`: **2.30** and `table`: **1.14** → These are within acceptable ranges.\n",
        "\n",
        "We saw that the VIF for 'x', 'y', 'z' are high. However, 'x', 'y', 'z' measures the dimension of the diamond and one would think these variables to be independent. Therefore, we created a new variable, namely 'volume' to address the problem of multicollinearity.\n",
        "\n",
        "\n",
        "```{r}\n",
        "data$volume <- data$x * data$y * data$z\n",
        "\n",
        "model_with_volume <- lm(price ~ carat + cut + color + clarity + depth + table + volume, data = data)\n",
        "vif_with_volume <- vif(model_with_volume)\n",
        "print(\"VIF for Model with Volume:\")\n",
        "print(vif_with_volume)\n",
        "\n",
        "\n",
        "model_without_volume <- lm(price ~ carat + cut + color + clarity + depth + table, data = data)\n",
        "vif_without_volume <- vif(model_without_volume)\n",
        "print(\"VIF for Model without Volume:\")\n",
        "print(vif_without_volume)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "From the above output, we can see that VIF's for carat and volume are above the general threshold of 5, suggesting multicollinearity. \n",
        "\n",
        "1. We can drop 'volume' since it is intuitive to think that 'carat' (weight) and 'volume' are related. Additionally, 'carat' seems more important of a measure for gemstones, as it is more commonly used in practice to measure gemstones. Keeping only `carat` simplifies the model and avoids redundancy. This is the ideal approach if we wish to retain the interpretability of the model.\n",
        "\n",
        "2. Another thing we can do is we can try using Principle Component Regression to address the multicollinearity between carat and volume. This is a good approach if we only wish to create a high accuracy prediction model and not necessarily retain interpretability.\n",
        "\n",
        "# Outlier Detection\n",
        "\n",
        "From the exploratory data analysis, we can see the presence of a lot of outliers. Here, we will address the problem of outliers.\n",
        "\n",
        "## Standardized Residuals\n",
        "\n",
        "\n",
        "```{r}\n",
        "# Standardized residuals\n",
        "model <- lm(price ~ carat + cut + clarity + depth + table, data = data)\n",
        "data$residuals <- rstandard(model)\n",
        "\n",
        "# Identify outliers\n",
        "outliers <- data %>% filter(abs(residuals) > 3)  # Residuals > 3 standard deviations\n",
        "print(nrow(outliers))\n",
        "print(outliers)\n",
        "\n",
        "```\n",
        "\n",
        "We can see that we have 586 outliers. This is 586/26967 * 100 ~ 2.17% of our data. Since we are not sure if these outliers are the result of data entry errors, etc, we will not remove the outliers as that may lead to deletion of useful information. \n",
        "\n",
        "# Regression Analysis After Dropping Volume\n",
        "\n",
        "## Stepwise Selection\n",
        "\n",
        "\n",
        "```{r}\n",
        "predictors <- c(\"carat\", \"cut\", \"color\", \"clarity\", \"depth\", \"table\") \n",
        "response <- \"price\"\n",
        "```\n",
        "\n",
        "\n",
        "# Fit initial and full models\n",
        "\n",
        "\n",
        "```{r}\n",
        "simple_model <- lm(as.formula(paste(response, \"~ 1\")), data = data)\n",
        "full_model <- lm(price ~ carat * clarity + cut + color + depth + table, data = data)\n",
        "\n",
        "stepwise_model <- stepAIC(simple_model, scope = list(lower = simple_model, upper = full_model), direction = \"both\")\n",
        "summary(stepwise_model)\n",
        "```\n",
        "\n",
        "Based on the EDA and due to computational cost, we only include 1 interaction term, namely 'carat:clarity' and assuming no interaction between the other covariates.\n",
        "\n",
        "```{r}\n",
        "par(mfrow = c(2, 2)) \n",
        "plot(stepwise_model)\n",
        "```\n",
        "\n",
        "The Residuals vs Fitted plot does not show homoscedasticity. The Q-Q plot also suggests that the residuals do not really follow a normal distribution. Therefore, we need to address by applying log transform on the response variable (price) and one of the covariates (carat).\n",
        "# Results and Interpretation\n",
        "\n",
        "\n",
        "```{r}\n",
        "# Calculate key metrics\n",
        "rss <- sum(resid(stepwise_model)^2)\n",
        "tss <- sum((data$price - mean(data$price))^2)\n",
        "r_squared <- 1 - (rss / tss)\n",
        "adjusted_r_squared <- 1 - ((1 - r_squared) * ((nrow(data) - 1) / (nrow(data) - length(coef(stepwise_model)) - 1)))\n",
        "\n",
        "# Create a summary table\n",
        "library(tibble)\n",
        "model_metrics <- tibble(\n",
        "  Metric = c(\"R²\", \"Adjusted R²\"),\n",
        "  Value = c(r_squared, adjusted_r_squared)\n",
        ")\n",
        "print(model_metrics)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Log Transformation\n",
        "\n",
        "\n",
        "```{r}\n",
        "data$log_price <- log(data$price) \n",
        "data$log_carat <- log(data$carat)\n",
        "\n",
        "# performing backward selection\n",
        "log_transformed_model <- lm(log_price ~ log_carat + cut + color + clarity + table + depth + log_carat:clarity, data = data)\n",
        "summary(log_transformed_model)\n",
        "\n",
        "# excluding table\n",
        "log_transformed_model <- lm(log_price ~ log_carat + cut + color + clarity + depth + log_carat:clarity, data = data)\n",
        "summary(log_transformed_model)\n",
        "\n",
        "# excluding depth\n",
        "log_transformed_model <-lm(log_price ~ log_carat + cut + color + clarity + log_carat:clarity, data = data)\n",
        "summary(log_transformed_model)\n",
        "```\n",
        "\n",
        "Based on the summary above, after applying log transformation on 'carat' and dropping 'depth', and 'table' we achieved better R^2 and adjusted R^2. This simpler model is easier for interpretation and has the same adjusted R^2 as the larger models. Since the interaction between some clarity levels and carat are significant, we have chosen to include it in the model. \n",
        "\n",
        "\n",
        "```{r}\n",
        "par(mfrow = c(2, 2)) \n",
        "plot(log_transformed_model)\n",
        "```\n",
        "\n",
        "Now, the residuals vs fitted plot suggests heteroscedasticity is less of a concern as the points are now centering around zero and have constant variance. However, another possible concern is that of a slight curve in the residuals, which might suggest a non-linear relationship. We have already included one non linear relationship - that of the interaction term, however it may not be enough.\n",
        "\n",
        "The Q-Q plot looks better than the previous model's, although the deviations at the end suggest a distribution with heavier tails rather than a normal distribution. Alternatively, it may also suggest the presence of outliers, which is present as analyzed previously. \n",
        "\n",
        "\n",
        "```{r}\n",
        "# Trying a cubic relationship between log(carat) and log(price)\n",
        "\n",
        "cubic_relation <- lm(log_price ~ log_carat + I(log_carat^2) + I(log_carat^3) + cut + color + clarity + \n",
        "    log_carat:clarity, data = data)\n",
        "\n",
        "summary(cubic_relation)\n",
        "\n",
        "plot(y = cubic_relation$residuals, x = cubic_relation$fitted.values, main = \"Residual Plot\")\n",
        "```\n",
        "\n",
        "\n",
        "Although the above cubic model has a higher adjusted R^2 : 0.9849 vs the old model :  0.9831, the additional complexity of the cubic model is not justified by the small increase of 0.0018 in R^2. The residual plot also doesn't look much better than the previous model. So even though the cubic log(carat) value is significant in the summary, we have decided to choose the more simplistic model as we have already captured some non-linearity with our interaction term between clarity and log_carat.\n",
        "\n",
        "Our final model for this section is $ log(price) = \\beta_0 + \\beta_1*log(carat) + \\beta_2*cut + \\beta_3*color + \\beta_4*clarity + \\beta_5*log(carat)*clarity $\n",
        "\n",
        "\n",
        "# Regression Analysis Using PCA To Address Multicollinearity\n",
        "\n",
        "We will now compare the above method of dropping the volume variable with the PCA method.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# Extracting carat and volume covariates into their own dataframe:\n",
        "\n",
        "data <- read_csv(file = path, col_names = TRUE) |> drop_na(depth)\n",
        "data$volume <- data$x * data$y * data$z\n",
        "\n",
        "subset_data <- data |> dplyr::select(volume, carat)\n",
        "head(subset_data)\n",
        "```\n",
        "\n",
        "```{r}\n",
        "# Applying PCA on standardized carat and volume\n",
        "\n",
        "pc_car_vol <- princomp(subset_data, cor = T)\n",
        "plot(pc_car_vol)\n",
        "\n",
        "```\n",
        "\n",
        "The above graph shows that most of the variance is captured by the first component. The code cell below calculates that around 98% of variance is captured by the first component. Therefore, we can now regress our model on only the first component as the second isn't needed given that it is only capturing around 2% of variation.\n",
        "\n",
        "\n",
        "```{r}\n",
        "lambdas <- pc_car_vol$sdev^2\n",
        "\n",
        "# Computing variation proportion captured by first X principal components\n",
        "( sum(lambdas[1]) / sum(lambdas) )  # First PC\n",
        "( sum(lambdas[1:2]) / sum(lambdas) )  # First two PCs\n",
        "```\n",
        "\n",
        "```{r}\n",
        "pcr_model <- lm(log(price) ~ (pc_car_vol$scores[,1]) + I(pc_car_vol$scores[,1]^2) + I(pc_car_vol$scores[,1]^3) + cut + color + clarity + clarity:pc_car_vol$scores[,1] + depth + table, data = data)\n",
        "summary(pcr_model)\n",
        "\n",
        "plot(y = pcr_model$residuals, x = pcr_model$fitted.values, main = \"Residual Plot\")\n",
        "qqnorm(pcr_model$residuals, pch = 1, frame = FALSE)\n",
        "qqline(pcr_model$residuals, col = \"steelblue\", lwd = 2)\n",
        "```\n",
        "\n",
        "The residual plot and qq-plot show similar concerns as the model fitted before. Namely, the qq plot's curve at the end suggests the presence of outliers or heavier tailed distribution of the residuals rather than a normal distribution. The residual plot also suggests the presence of some outliers. There is not as much concern for heteroscedasticity.\n",
        "\n",
        "As seen above, the pca model required a cubic first principal component and two more covariates: namely depth and table, to be approximately the same adjusted R^2 as the previous method's model. The previous model's adjusted R^2 was 0.9831 and the pcr model's adjusted R^2 is 0.9787. This is a difference of 0.0044, which is rather insignificant. This suggests that while both method perform similarly in explaining the variation in the data, the first model (created by dropping the volume covariate), is better as it is simpler to interpret. This choice is in line with the principle of parsimony. Therefore, we conclude the better model for this data is the model created by dropping the volume variable:\n",
        "\n",
        "$ log(price) = \\beta_0 + \\beta_1*log(carat) + \\beta_2*cut + \\beta_3*color + \\beta_4*clarity + \\beta_5*log(carat)*clarity $\n"
      ],
      "id": "096d48f1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}